<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Yicheng Chen</title>
    <link>https://amos-chen98.github.io/project/</link>
      <atom:link href="https://amos-chen98.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 11 Nov 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://amos-chen98.github.io/media/icon_hu0ee3cac1b031394232b0fce022e2944b_69873_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://amos-chen98.github.io/project/</link>
    </image>
    
    <item>
      <title>Cooperative Online Trajectory Planning for Autonomous Aerial Robotics Swarm</title>
      <link>https://amos-chen98.github.io/project/master_thesis/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://amos-chen98.github.io/project/master_thesis/</guid>
      <description>&lt;!-- Aim: (1) Full autonomy: Fully onboard perception, self-positioning, planning, and control. (2) Online: Real-time flying in
unknown environments. (3) Cooperation: Multiple drones to perform cooperative tasks, such as search and rescue. --&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;November 11, 2022&lt;/strong&gt;. That&amp;rsquo;s it, this project is started!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;project-objectives&#34;&gt;Project objectives&lt;/h2&gt;
&lt;p&gt;This project aims to address the issue: How to enable agile flight for aerial robotics swarm in complex environments? The main considerations of this projects include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Full autonomy&lt;/strong&gt;: Fully onboard perception, localization, planning, and control.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online&lt;/strong&gt;: Real-time flying in unknown environments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cooperation&lt;/strong&gt;: Multiple drones to perform cooperative tasks, such as search and rescue.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;roadmap&#34;&gt;Roadmap&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WP1: Trajectory parameterization&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Parameterize trajectories in a spatial-temporal-decoupled form to support independent optimization on the spatial and temporal profile of the trajectory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WP2: Distributed trajectory planning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Build an optimization framework considering control effort, execution time, dynamic feasibility, obstacle avoidance, and swarm reciprocal avoidance. And use gradient-based solvers to solve the problem.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;WP3: Real-world experiments&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Build quadrotors equipped with depth cameras, Intel NUC, and the Pixhawk controller to conduct real-world experiments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Radiograph Classification for Diagnosing COVID-19</title>
      <link>https://amos-chen98.github.io/project/covid_classification/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://amos-chen98.github.io/project/covid_classification/</guid>
      <description>&lt;h2 id=&#34;aim&#34;&gt;Aim&lt;/h2&gt;
&lt;p&gt;Use machine learning approaches to help preliminary diagnosis of chest radiographs: classify radiographs into 3 classes
â€“ COVID, normal, and viral pneumonia with the highest possible accuracy.&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Used transfer learning to train several models including ResNet, DenseNet, InceptionResNet, etc. on a labeled
training set.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/Amos-Chen98/Image_bed/main/2022/202212042009814.png&#34; alt=&#34;image-20221204200941644&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Used stacking to ensemble the above models to form a stronger model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/Amos-Chen98/Image_bed/main/2022/202212042010519.png&#34; alt=&#34;image-20221204201004347&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;achievement&#34;&gt;Achievement&lt;/h2&gt;
&lt;p&gt;Achieved accuracy of more than 0.98. Especially, the model achieved almost 100% precision in the COVID
class.&lt;/p&gt;
&lt;center&gt;Model performance on test set&lt;/center&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://raw.githubusercontent.com/Amos-Chen98/Image_bed/main/2022/202212041959570.png&#34; alt=&#34;caption&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
